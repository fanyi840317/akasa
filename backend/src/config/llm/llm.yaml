# LLM 配置文件
# Large Language Model Configuration
# =============================================================================
providers:
  # OpenAI Configuration
  openai:
    api_key: ${OPENAI_API_KEY}
    base_url: ${OPENAI_BASE_URL:https://api.openai.com/v1}
    organization: ${OPENAI_ORG_ID:}
    models:
      basic: gpt-4o-mini
      reasoning: gpt-4o
      vision: gpt-4o
      fast: gpt-3.5-turbo
      embedding: text-embedding-ada-002
      code: gpt-4o
      research: gpt-4o
      analysis: gpt-4o
    model_configs:
      basic:
        model: gpt-4o-mini
        temperature: 0.7
        max_tokens: 4000
      reasoning:
        model: gpt-4o
        temperature: 0.3
        max_tokens: 8000
      vision:
        model: gpt-4o
        temperature: 0.5
        max_tokens: 4000
      fast:
        model: gpt-3.5-turbo
        temperature: 0.7
        max_tokens: 2000
      code:
        model: gpt-4o
        temperature: 0.1
        max_tokens: 6000
      research:
        model: gpt-4o
        temperature: 0.3
        max_tokens: 8000
      analysis:
        model: gpt-4o
        temperature: 0.2
        max_tokens: 6000
      default_params:
        temperature: 0.3
        max_tokens: 4000
        top_p: 1.0
        frequency_penalty: 0.0
        presence_penalty: 0.0

  # Anthropic Claude Configuration
  anthropic:
    api_key: ${ANTHROPIC_API_KEY}
    base_url: ${ANTHROPIC_BASE_URL:https://api.anthropic.com}
    models:
      basic: claude-3-haiku-20240307
      reasoning: claude-3-5-sonnet-20241022
      vision: claude-3-5-sonnet-20241022
      fast: claude-3-haiku-20240307
      embedding: # Anthropic doesn't provide embedding models
      code: claude-3-5-sonnet-20241022
      research: claude-3-5-sonnet-20241022
      analysis: claude-3-5-sonnet-20241022
    model_configs:
      basic:
        model: claude-3-haiku-20240307
        temperature: 0.7
        max_tokens: 4000
      reasoning:
        model: claude-3-5-sonnet-20241022
        temperature: 0.3
        max_tokens: 8000
      vision:
        model: claude-3-5-sonnet-20241022
        temperature: 0.5
        max_tokens: 4000
      fast:
        model: claude-3-haiku-20240307
        temperature: 0.7
        max_tokens: 2000
      code:
        model: claude-3-5-sonnet-20241022
        temperature: 0.1
        max_tokens: 6000
      research:
        model: claude-3-5-sonnet-20241022
        temperature: 0.3
        max_tokens: 8000
      analysis:
        model: claude-3-5-sonnet-20241022
        temperature: 0.2
        max_tokens: 6000
    default_params:
      temperature: 0.3
      max_tokens: 4000
      top_p: 1.0

  # Google Gemini Configuration
  google:
    api_key: ${GOOGLE_API_KEY}
    base_url: ${GOOGLE_BASE_URL:https://generativelanguage.googleapis.com/v1}
    models:
      basic: gemini-1.5-flash
      reasoning: gemini-1.5-pro
      vision: gemini-1.5-pro
      fast: gemini-1.5-flash
      embedding: embedding-001
      code: gemini-1.5-pro
      research: gemini-1.5-pro
      analysis: gemini-1.5-pro
    model_configs:
      basic:
        model: gemini-1.5-flash
        temperature: 0.7
        max_tokens: 4000
      reasoning:
        model: gemini-1.5-pro
        temperature: 0.3
        max_tokens: 8000
      vision:
        model: gemini-1.5-pro
        temperature: 0.5
        max_tokens: 4000
      fast:
        model: gemini-1.5-flash
        temperature: 0.7
        max_tokens: 2000
      code:
        model: gemini-1.5-pro
        temperature: 0.1
        max_tokens: 6000
      research:
        model: gemini-1.5-pro
        temperature: 0.3
        max_tokens: 8000
      analysis:
        model: gemini-1.5-pro
        temperature: 0.2
        max_tokens: 6000
    default_params:
      temperature: 0.3
      max_output_tokens: 4000
      top_p: 1.0
      top_k: 40

  # Qwen Configuration (阿里云通义千问)
  qwen:
    api_key: ${QWEN_API_KEY}
    base_url: ${QWEN_BASE_URL:https://dashscope.aliyuncs.com/api/v1}
    models:
      basic: qwen2.5-7b-instruct
      reasoning: qwen2.5-72b-instruct
      vision: qwen2-vl-72b-instruct
      fast: qwen2.5-3b-instruct
      embedding: text-embedding-v1
      code: qwen2.5-coder-32b-instruct
      research: qwen2.5-72b-instruct
      analysis: qwen2.5-72b-instruct
    model_configs:
      basic:
        model: qwen2.5-7b-instruct
        temperature: 0.7
        max_tokens: 4000
      reasoning:
        model: qwen2.5-72b-instruct
        temperature: 0.3
        max_tokens: 8000
      vision:
        model: qwen2-vl-72b-instruct
        temperature: 0.5
        max_tokens: 4000
      fast:
        model: qwen2.5-3b-instruct
        temperature: 0.7
        max_tokens: 2000
      code:
        model: qwen2.5-coder-32b-instruct
        temperature: 0.1
        max_tokens: 6000
      research:
        model: qwen2.5-72b-instruct
        temperature: 0.3
        max_tokens: 8000
      analysis:
        model: qwen2.5-72b-instruct
        temperature: 0.2
        max_tokens: 6000
    default_params:
      temperature: 0.3
      max_tokens: 4000
      top_p: 1.0
      repetition_penalty: 1.1

  # Ollama Configuration (本地部署)
  ollama:
    base_url: ${OLLAMA_BASE_URL:http://localhost:11434}
    models:
      basic: llama2:7b
      reasoning: llama2:13b
      vision: llava:7b
      fast: llama2:7b
      embedding: nomic-embed-text
      code: codellama:7b
      research: llama2:13b
      analysis: llama2:13b
    default_params:
      temperature: 0.3
      num_predict: 4000
      top_p: 1.0
      repeat_penalty: 1.1

  # Zhipu AI Configuration (智谱AI)
  zhipu:
    api_key: ${ZHIPU_API_KEY}
    base_url: ${ZHIPU_BASE_URL:https://open.bigmodel.cn/api/paas/v4}
    models:
      basic: glm-3-turbo
      reasoning: glm-4
      vision: glm-4v
      fast: glm-3-turbo
      embedding: embedding-2
      code: codegeex2-6b
      research: glm-4
      analysis: glm-4
    default_params:
      temperature: 0.3
      max_tokens: 4000
      top_p: 1.0

  # Baidu ERNIE Configuration (百度文心一言)
  baidu:
      api_key: ${BAIDU_API_KEY}
      secret_key: ${BAIDU_SECRET_KEY}
      base_url: ${BAIDU_BASE_URL:https://aip.baidubce.com}
      models:
        basic: ernie-bot-turbo
        reasoning: ernie-bot-4
        vision: ernie-bot-4
        fast: ernie-bot-turbo
        embedding: embedding-v1
        code: ernie-bot-4
        research: ernie-bot-4
        analysis: ernie-bot-4
      default_params:
        temperature: 0.3
        max_output_tokens: 4000
        top_p: 1.0


# LLM type to provider mapping (可以为不同类型指定不同的提供商)
type_provider_mapping:
  basic:
    - openai
    - qwen
    - ollama
  reasoning:
    - anthropic
    - openai
    - qwen
  vision:
    - openai
    - google
    - qwen
  fast:
    - openai
    - qwen
    - ollama
  embedding:
    - openai
    - qwen
    - google
  code:
    - openai
    - anthropic
    - qwen
  research:
    - anthropic
    - openai
    - qwen
  analysis:
    - anthropic
    - openai
    - qwen

# Fallback configuration
fallback:
  enabled: true
  max_retries: 3
  retry_delay: 1.0